{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09db4e6e-5d28-4636-abca-c33af3406765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import ot\n",
    "\n",
    "import geomstats\n",
    "from geomstats.geometry.spd_matrices import SPDMatrices\n",
    "\n",
    "from dtmrpy import DT_GMM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411b0591-5fe4-4581-9de8-7ba1c5b1ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dtgmm:\n",
    "    def __init__(self, weights, locations):\n",
    "        assert weights.shape[0] == locations.shape[0]\n",
    "        self.weights = weights\n",
    "        self.locations = locations\n",
    "     \n",
    "    def means_(self):\n",
    "        return self.locations[:,:3]\n",
    "    \n",
    "    def covariances_(self):\n",
    "        C = self.locations[:,3:]\n",
    "        return np.array([C[:,0],C[:,1]/2,C[:,2]/2,C[:,1]/2,C[:,3],C[:,4]/2,C[:,2]/2,C[:,4]/2,C[:,5]]).T.reshape(-1,3,3)\n",
    "        \n",
    "    def plot_gmm(self):\n",
    "        w = self.weights/max(self.weights)\n",
    "        x,y,z = self.locations[:,0],self.locations[:,1],self.locations[:,2]\n",
    "        c = np.array([self.locations[:,3],self.locations[:,6],self.locations[:,8]]).T\n",
    "        c=c/(np.sum(c,1).reshape(-1,1))\n",
    " \n",
    "        for i in range(w.shape[0]):\n",
    "            plt.plot(x[i],y[i],z[i],'.',c=c[i],alpha = w[i])\n",
    "            \n",
    "        # plt.gca().scatter(x,y,z,s=8,c=c, alpha = w)\n",
    "\n",
    "def DT_GMM_to_dtgmm(DT_GMM):\n",
    "    w = DT_GMM.weights_.reshape(-1)\n",
    "    weights = w/sum(w)\n",
    "    \n",
    "    x = DT_GMM.means_\n",
    "    x = x-np.mean(x,0)\n",
    "    cov_temp = geomstats.geometry.spd_matrices.SPDMatrices(3).projection(DT_GMM.covariances_)\n",
    "    C = (cov_temp.reshape(-1,9)[:,np.array([0,1,2,4,5,8])])*(np.array([1,2,2,1,2,1]).reshape(1,-1))   \n",
    "    locations = np.concatenate([x,C],1)\n",
    "    \n",
    "    return dtgmm(weights, locations)\n",
    "\n",
    "def dtgmm_to_DT_GMM(dtgmm):\n",
    "    weights_ = dtgmm.weights\n",
    "    means_ = dtgmm.locations[:,:3]\n",
    "    dtgmm.covariances_\n",
    "    return DT_GMM(weights_,means_,covarinaces_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c6a9f7-62ee-4a1a-a5ed-4e41f23d516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class free_support_barycenter(dtgmm):\n",
    "    \n",
    "    def __init__(self,barycenter=None, N=200, lr=0.0000001):\n",
    "        self.lr=lr #learning rate for weights update\n",
    "        \n",
    "        if barycenter==None:\n",
    "            init_weights = np.ones(N)/N\n",
    "            x = np.zeros(3)+np.random.normal(size=(N,3))\n",
    "            cov_temp = geomstats.geometry.spd_matrices.SPDMatrices(3).random_point(N)\n",
    "            C = (cov_temp.reshape(-1,9)[:,np.array([0,1,2,4,5,8])])*(np.array([1,2,2,1,2,1]).reshape(1,-1)) \n",
    "            init_locations = np.concatenate([x,C],1)\n",
    "            \n",
    "            super().__init__(init_weights, init_locations)\n",
    "            self.N = N\n",
    "        \n",
    "        else:\n",
    "            super().__init__(barycenter.weights, barycenter.locations)\n",
    "            self.N = barycenter.weights.shape[0]\n",
    "               \n",
    "    def get_barycentric_projection_embedding(self, measures_list):\n",
    "        self.M_list = [np.square(cdist(self.locations,measure.locations)) for measure in measures_list]\n",
    "        #calculate optimal couplings and optimal dual variables\n",
    "        result_list = [ot.emd(self.weights,measure.weights,self.M_list[i],log=True) for i, measure in enumerate(measures_list)]\n",
    "        #store optimal couplings\n",
    "        self.Pi_list = [result[0] for result in result_list]\n",
    "        #store optimal dual variables - center_ot_dual can probably just be replaced with result[1]['u']-np.mean(result[1]['u'])\n",
    "        self.alpha_list = [ot.lp.center_ot_dual(result[1]['u'],result[1]['v'])[0] for result in result_list]\n",
    "        #calculate and store barycentric projection locations\n",
    "        self.embedding = np.array([(measures_list[i].locations.T@self.Pi_list[i].T@np.diag(1/self.weights.reshape(-1))).T for i in range(len(measures_list))])\n",
    "\n",
    "    def weights_update(self):\n",
    "        #get subgradient\n",
    "        alpha = np.mean(np.array(self.alpha_list),0)\n",
    "        #calculate subgradient update\n",
    "        a_star = self.weights+(self.lr*alpha.reshape(1,-1))\n",
    "        #project a_star into (interior of) probability simplex\n",
    "        a_star[a_star<0]=1e-8\n",
    "        a = a_star/np.sum(a_star)\n",
    "\n",
    "        return a.reshape(-1)\n",
    "        \n",
    "    def free_support_barycenter_update(self, measures_list):\n",
    "        self.get_barycentric_projection_embedding(measures_list)\n",
    "        self.locations = np.mean(self.embedding,0)\n",
    "        self.weights = self.weights_update()\n",
    "        # print(np.mean(np.square(np.linalg.norm(barycenter.pseudo_log(),axis=1))))\n",
    "        \n",
    "    def pseudo_log(self):\n",
    "        #calculate vector field representations\n",
    "        return (self.embedding - self.locations).reshape(-1,self.N*9)\n",
    "    \n",
    "    def fit(self, measures_list, K=10, plot_steps=False):\n",
    "        \n",
    "        for i in range(K):\n",
    "            self.free_support_barycenter_update(measures_list)\n",
    "            \n",
    "            if plot_steps:\n",
    "                plt.figure().add_subplot(projection='3d')\n",
    "                barycenter.plot_gmm()\n",
    "                plt.gca().view_init(35,135)\n",
    "                plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c884afe-de84-4647-b791-c8fcd41a98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.load('D:/DTMRI/HCP/hcp_centered_full_MZ_removed.pkl', allow_pickle=True)\n",
    "keep_columns = list(df.columns[:2])+list(df.columns[4:12])+list(df.columns[16:18])+list(df.columns[24:-1])\n",
    "df = df[keep_columns].dropna()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1bb53c8-6491-41e6-8bc8-34a820eb98b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\envs\\gpu_compute_env\\Lib\\site-packages\\ot\\lp\\__init__.py:354: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  result_code_string = check_result(result_code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\envs\\gpu_compute_env\\Lib\\site-packages\\ot\\lp\\__init__.py:354: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  result_code_string = check_result(result_code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 4 5 6 7 8 9 10 11 "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut\n",
    "\n",
    "# X_list2=[]\n",
    "for k in [200]:\n",
    "    X_list=[]\n",
    "\n",
    "    for i, tract in enumerate(df.columns[2:]):\n",
    "        print(i, end=' ')\n",
    "\n",
    "        #get tract data\n",
    "        ind = df[tract].dropna().index\n",
    "        measure_list = list(df[tract][ind])\n",
    "        dtgmm_list = [DT_GMM_to_dtgmm(measure) for measure in measure_list]\n",
    "        y = np.array((df['label'][ind]=='M').astype(int))\n",
    "\n",
    "        #calculate barycenter\n",
    "        #initialize barycenter with k support points\n",
    "        barycenter = free_support_barycenter(N=k)\n",
    "\n",
    "        #fit k-support barycenter to data\n",
    "        barycenter.fit(dtgmm_list)\n",
    "\n",
    "        #get barycentric_projections\n",
    "        X_list.append((barycenter.embedding - barycenter.locations)[:,:,3:].reshape(len(y),-1))\n",
    "\n",
    "    X_list2.append(X_list)\n",
    "    # Z = np.array([x.T for x in X_list]).reshape(-1,739).T\n",
    "    # print(' ')\n",
    "    # print(k, np.mean(cross_val_score(SVC(kernel='rbf', probability=True),Z,y,cv=10)))\n",
    "    # print(' ')\n",
    "\n",
    "# test = np.array([cross_val_predict(SVC(kernel='rbf', probability=True),x,y,cv=cv, method='predict_proba')[:,1] for x in X_list])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a4bd6c2b-5121-4c9d-8674-96ba2550c6e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_list2_5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mX_list2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "np.save(\"X_list2_5\",X_list2[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6da1e67-16f4-485c-aff7-0c450ebf0581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 739, 6)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('X_list2_0.npy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "18af74cd-d0a6-400f-9028-786c4775221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.591339648173207\n",
      "1 0.6359945872801083\n",
      "2 0.6684709066305818\n",
      "3 0.6684709066305818\n",
      "4 0.6847090663058186\n",
      "5 0.6901217861975643\n",
      "6 0.6982408660351827\n",
      "7 0.6874154262516915\n",
      "8 0.6901217861975643\n",
      "9 0.6901217861975643\n",
      "10 0.6955345060893099\n",
      "11 0.6928281461434371\n",
      "0.6928281461434371\n",
      " \n",
      "0 0.6630581867388363\n",
      "1 0.6955345060893099\n",
      "2 0.7212449255751014\n",
      "3 0.7266576454668471\n",
      "4 0.7469553450608931\n",
      "5 0.7456021650879567\n",
      "6 0.7469553450608931\n",
      "7 0.7469553450608931\n",
      "8 0.7456021650879567\n",
      "9 0.7415426251691475\n",
      "10 0.7523680649526387\n",
      "11 0.7510148849797023\n",
      "0.7510148849797023\n",
      " \n",
      "0 0.6806495263870095\n",
      "1 0.6820027063599459\n",
      "2 0.7280108254397835\n",
      "3 0.7428958051420839\n",
      "4 0.7469553450608931\n",
      "5 0.7469553450608931\n",
      "6 0.7510148849797023\n",
      "7 0.7428958051420839\n",
      "8 0.7456021650879567\n",
      "9 0.7428958051420839\n",
      "10 0.7550744248985115\n",
      "11 0.7523680649526387\n",
      "0.7523680649526387\n",
      " \n",
      "0 0.6698240866035182\n",
      "1 0.6738836265223275\n",
      "2 0.7253044654939107\n",
      "3 0.7374830852503383\n",
      "4 0.7374830852503383\n",
      "5 0.7320703653585927\n",
      "6 0.7374830852503383\n",
      "7 0.7347767253044655\n",
      "8 0.7374830852503383\n",
      "9 0.7428958051420839\n",
      "10 0.7469553450608931\n",
      "11 0.7496617050067659\n",
      "0.7496617050067659\n",
      " \n",
      "0 0.6738836265223275\n",
      "1 0.6779431664411367\n",
      "2 0.7198917456021651\n",
      "3 0.7374830852503383\n",
      "4 0.7361299052774019\n",
      "5 0.7374830852503383\n",
      "6 0.7374830852503383\n",
      "7 0.7388362652232747\n",
      "8 0.7415426251691475\n",
      "9 0.7442489851150202\n",
      "10 0.7456021650879567\n",
      "11 0.7510148849797023\n",
      "0.7510148849797023\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for X in X_list2:\n",
    "    y_hat=[]\n",
    "    for i, x in enumerate(X):\n",
    "        print(i, end=' ')\n",
    "        y_hat.append(cross_val_predict(SVC(kernel='rbf', probability=True),x,y,cv=10, method='predict_proba')[:,1])\n",
    "        print(np.mean((np.mean(np.array(y_hat),0)>.5).astype(int)==y))\n",
    "        \n",
    "    print(np.mean((np.mean(np.array(y_hat),0)>.5).astype(int)==y))\n",
    "    print(\" \")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_compute_env",
   "language": "python",
   "name": "gpu_compute_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
